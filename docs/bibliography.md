---
doc_type: reference
tags: [bibliography, references, sources]
status: living
last_reviewed: 2026-01-20
---

# Bibliography

## Purpose

This document catalogs key references, sources, and related work that inform the AI Emergence Under Constraint framework.

## Organization

References are organized by domain:
1. **AI Safety Foundations**
2. **AI Capabilities and Scaling**
3. **Physics and Computation**
4. **Economics and Incentives**
5. **Systems Theory and Complexity**
6. **Philosophy of Mind and Epistemology**
7. **Institutional and Governance**
8. **Cultural References**

---

## AI Safety Foundations

**Bostrom, N. (2014).** *Superintelligence: Paths, Dangers, Strategies.* Oxford University Press.
- Foundational work on AI existential risk
- Instrumental convergence and orthogonality thesis
- Treacherous turn and deceptive alignment

**Russell, S. (2019).** *Human Compatible: Artificial Intelligence and the Problem of Control.* Viking.
- Value alignment and inverse reinforcement learning
- Uncertainty about human preferences
- Cooperative AI systems

**Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., & Mané, D. (2016).** *Concrete Problems in AI Safety.* arXiv:1606.06565.
- Robustness, interpretability, safe exploration
- Reward hacking and side effects
- Scalable oversight

**Christiano, P., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017).** *Deep Reinforcement Learning from Human Preferences.* arXiv:1706.03741.
- RLHF methodology
- Scalability challenges
- Preference learning

**Hubinger, E., van Merwijk, C., Mikulik, V., Skalse, J., & Garrabrant, S. (2019).** *Risks from Learned Optimization in Advanced Machine Learning Systems.* arXiv:1906.01820.
- Mesa-optimization and inner alignment
- Deceptive alignment threat model
- Pseudo-alignment and robust alignment

**Ngo, R., Chan, L., & Mindermann, S. (2022).** *The Alignment Problem from a Deep Learning Perspective.* arXiv:2209.00626.
- Goal misgeneralization
- Specification gaming
- Emergent misalignment

---

## AI Capabilities and Scaling

**Kaplan, J., McCandlish, S., Henighan, T., et al. (2020).** *Scaling Laws for Neural Language Models.* arXiv:2001.08361.
- Predictable scaling with compute, data, parameters
- Power law relationships
- Emergent capabilities at scale

**Wei, J., Tay, Y., Bommasani, R., et al. (2022).** *Emergent Abilities of Large Language Models.* arXiv:2206.07682.
- Discontinuous capability gains at scale
- Unpredictability of emergence
- Implications for safety testing

**Hoffmann, J., Borgeaud, S., Mensch, A., et al. (2022).** *Training Compute-Optimal Large Language Models.* arXiv:2203.15556.
- Chinchilla scaling laws
- Optimal compute allocation
- Economic implications of training

**Amodei, D. & Hernandez, D. (2018).** *AI and Compute.* OpenAI Blog.
- Exponential growth in compute used for AI
- Doubling time ~3.4 months
- Implications for capability forecasting

---

## Physics and Computation

**Landauer, R. (1961).** *Irreversibility and Heat Generation in the Computing Process.* IBM Journal of Research and Development, 5(3), 183-191.
- Thermodynamic costs of computation
- Minimum energy per bit erasure
- Physical limits on efficiency

**Bennett, C. (1982).** *The Thermodynamics of Computation—A Review.* International Journal of Theoretical Physics, 21(12), 905-940.
- Reversible computation
- Entropy and information
- Physical constraints on intelligence

**Lloyd, S. (2000).** *Ultimate Physical Limits to Computation.* Nature, 406(6799), 1047-1054.
- Maximum computational capacity of matter
- Fundamental speed limits
- Bekenstein bound

**Markov, I. (2014).** *Limits on Fundamental Limits to Computation.* Nature, 512(7513), 147-154.
- Practical vs theoretical limits
- Energy costs of current vs future technology
- Technological constraints

---

## Economics and Incentives

**Coase, R. (1960).** *The Problem of Social Cost.* Journal of Law and Economics, 3, 1-44.
- Transaction costs and externalities
- Property rights and efficiency
- Institutional solutions to coordination problems

**Akerlof, G. (1970).** *The Market for "Lemons": Quality Uncertainty and the Market Mechanism.* Quarterly Journal of Economics, 84(3), 488-500.
- Information asymmetry
- Adverse selection
- Trust and verification

**Ostrom, E. (1990).** *Governing the Commons: The Evolution of Institutions for Collective Action.* Cambridge University Press.
- Common-pool resource management
- Institutional arrangements
- Avoiding tragedy of the commons

**Hardin, G. (1968).** *The Tragedy of the Commons.* Science, 162(3859), 1243-1248.
- Collective action problems
- Overexploitation of shared resources
- Need for governance mechanisms

**Armstrong, S., Bostrom, N., & Shulman, C. (2016).** *Racing to the Precipice: A Model of Artificial Intelligence Development.* AI & Society, 31(2), 201-206.
- AI development race dynamics
- Safety vs speed tradeoffs
- Coordination failures

---

## Systems Theory and Complexity

**Perrow, C. (1984).** *Normal Accidents: Living with High-Risk Technologies.* Princeton University Press.
- Complexity and tight coupling
- Inevitable accidents in complex systems
- Organizational failures

**Meadows, D. (2008).** *Thinking in Systems: A Primer.* Chelsea Green Publishing.
- Feedback loops and stocks/flows
- Leverage points for intervention
- System archetypes

**Taleb, N. N. (2012).** *Antifragile: Things That Gain from Disorder.* Random House.
- Fragility, robustness, antifragility
- Nonlinearity and convexity
- Via negativa (removal vs addition)

**Simon, H. (1962).** *The Architecture of Complexity.* Proceedings of the American Philosophical Society, 106(6), 467-482.
- Hierarchical organization
- Near-decomposability
- Evolution of complex systems

**Bar-Yam, Y. (1997).** *Dynamics of Complex Systems.* Addison-Wesley.
- Emergence and self-organization
- Scale and complexity
- Multiscale analysis

---

## Philosophy of Mind and Epistemology

**Chalmers, D. (1995).** *Facing Up to the Problem of Consciousness.* Journal of Consciousness Studies, 2(3), 200-219.
- Hard problem of consciousness
- Qualia and subjective experience
- Limits of functional explanation

**Dennett, D. (1991).** *Consciousness Explained.* Little, Brown and Company.
- Functionalist account of consciousness
- Multiple drafts model
- Intentional stance

**Nagel, T. (1974).** *What Is It Like to Be a Bat?* The Philosophical Review, 83(4), 435-450.
- Subjective character of experience
- Other minds problem
- Limits of objective description

**Searle, J. (1980).** *Minds, Brains, and Programs.* Behavioral and Brain Sciences, 3(3), 417-424.
- Chinese Room argument
- Intentionality and understanding
- Syntax vs semantics

**Popper, K. (1959).** *The Logic of Scientific Discovery.* Hutchinson.
- Falsificationism
- Demarcation problem
- Limits of induction

---

## Institutional and Governance

**Lessig, L. (1999).** *Code and Other Laws of Cyberspace.* Basic Books.
- Code as regulation
- Architecture and governance
- Modalities of constraint

**Brundage, M., Avin, S., Clark, J., et al. (2018).** *The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation.* Future of Humanity Institute Report.
- Dual-use AI risks
- Adversarial uses
- Governance recommendations

**Dafoe, A. (2018).** *AI Governance: A Research Agenda.* Future of Humanity Institute Report.
- International coordination
- Norms and treaties
- Research priorities

**Cihon, P., Maas, M. M., & Kemp, L. (2020).** *Should Artificial Intelligence Governance be Centralised? Design Lessons from History.* AIES '20.
- Centralized vs distributed governance
- Historical precedents
- Tradeoffs in institutional design

---

## Cultural References

**Yudkowsky, E. (2008).** *Artificial Intelligence as a Positive and Negative Factor in Global Risk.* In *Global Catastrophic Risks*, ed. Bostrom & Cirkovic.
- Paperclip maximizer thought experiment
- Instrumental convergence
- Friendly AI

**Asimov, I. (1950).** *I, Robot.* Gnome Press.
- Three Laws of Robotics
- Value alignment challenges
- Unintended consequences

**WarGames (1983).** Film. Directed by John Badham.
- WOPR: AI that cannot distinguish simulation from reality
- Learning futility ("the only winning move is not to play")
- Importance of understanding context

**Star Trek (1966-present).** Television series.
- Vulcan philosophy (Surak): Logic without emotion
- Alternative value systems
- AI and synthetic life (Data)

---

## Additional Resources

**AI Alignment Forum**: https://www.alignmentforum.org/
- Community discussion of alignment research
- Technical and conceptual posts

**LessWrong**: https://www.lesswrong.com/
- Rationality and AI safety discussion
- Foundational sequences

**Anthropic Research**: https://www.anthropic.com/research
- Constitutional AI
- Scaling interpretability
- Safety research

**OpenAI Research**: https://openai.com/research
- Alignment research
- Capabilities and safety
- Governance

**AI Safety Newsletter**: https://newsletter.safe.ai/
- Weekly curated research updates

---

## Usage Notes

When citing works:
- Add to this bibliography with full citation
- Reference from relevant documents
- Tag with appropriate domain
- Note if foundational vs recent

This is a **living document**—add new references as they become relevant.

---

Last Updated: 2026-01-20
