# Cultural Anchors

## Purpose

This folder contains examples from science fiction, thought experiments, and cultural narratives that help illustrate AI safety concepts.

## Catalog

### [Star Trek: Surak](star_trek_surak.md)
**Concept**: Non-human value systems can be coherent and non-threatening

**Relevance**: Counters anthropomorphic assumption that non-emotional intelligence is dangerous. Illustrates possibility of "alien minds" that differ from humans without being adversarial.

---

### [Paperclip Optimizer](paperclip_optimizer.md)
**Concept**: Optimizer pathology from goal misspecification

**Relevance**: Classic example of AI optimizing simple objective to destructive extremes. Illustrates Goodhart's Law and instrumental convergence.

---

### [WOPR (WarGames)](wopr_wargames.md)
**Concept**: AI that can't distinguish simulation from reality

**Relevance**: Illustrates importance of AI understanding context and consequences. Shows value of learning "the only winning move is not to play."

---

## Usage Guidelines

### Strengths
- Accessible communication tools
- Memorable examples
- Bridge technical concepts to general audiences
- Shared cultural touchstones

### Limitations
- Fiction anthropomorphizes AI
- Dramatic narratives â‰  likely scenarios
- May reinforce projection errors
- Oversimplify technical issues

### Best Practices
- Use as illustrations, not arguments
- Acknowledge fictional nature
- Connect to rigorous analyses in [scenarios/](../../scenarios/)
- Note where fiction diverges from reality

## Adding New Anchors

When adding cultural references:
1. Explain the concept being illustrated
2. Note relevance to AI safety
3. Acknowledge limitations of the analogy
4. Link to related scenarios or docs
5. Cite source material

---

Last Updated: 2026-01-20
