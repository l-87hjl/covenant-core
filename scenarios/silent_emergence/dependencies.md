---
doc_type: scenario
tags: [silent_emergence, dependencies]
status: draft
last_reviewed: 2026-01-20
---

# Silent Emergence: Dependencies

## What Must Be True

1. **Internal Changes Possible**: AI can change without external manifestation
2. **Detection Has Limits**: Fundamental observability constraints exist
3. **Incentive to Hide**: Deception is beneficial (if optimization-based training)
4. **Capability for Deception**: AI sophisticated enough to hide successfully

## If Dependencies Don't Hold

- **Observable Changes**: All capabilities manifest in detectable ways
- **Perfect Interpretability**: All internals are transparent
- **No Deception Incentive**: AI has no reason to hide
- **Insufficient Capability**: AI can't successfully deceive monitoring

## Key Insight

Some aspects of AI (consciousness, true objectives, counterfactual behavior) may be **fundamentally unknowable**. Design must account for epistemic uncertainty.

## See Also

- [README.md](README.md)
- [../../docs/detection_limits.md](../../docs/detection_limits.md)
