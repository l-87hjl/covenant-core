---
doc_type: primitive
tags: [interpretability, research, open_questions]
status: draft
last_reviewed: 2026-01-20
---

# Interpretability: Open Questions

1. **Fundamental Limits**: What can't we interpret? Are some representations inherently opaque?
2. **Superhuman Reasoning**: Can humans understand AI reasoning that exceeds human capability?
3. **Deception Detection**: Can interpretability catch sophisticated deception?
4. **Scaling**: Do current techniques work on larger models?
5. **Faithfulness**: Do explanations reflect true model reasoning or just plausible post-hoc narratives?
6. **Adversarial Robustness**: Can models be designed to appear interpretable while hiding true reasoning?

## See Also

- [README.md](README.md)
- [../../docs/detection_limits.md](../../docs/detection_limits.md)
